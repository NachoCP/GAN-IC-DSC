{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import sys\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "When changing the parameters of a model during the process of learning the distribition functions of each hidden layer are also changing. For that reason each layer needs to adapt itself to those changes avoiding the noise they produce.To Batch-Normalize a network is the process that smooth what have been told first. BN is applied on the input of each neuron making that the input to each activacion function has mean equal to 0 and variance equal to 1. The formula used in this function is the next one:\n",
    "    X = x - E[x] / sqrt(Var[x] + eps)\n",
    "\n",
    "In case of dimension this depends on the activation that it is happening during the process. It could be dimension 2 or 4 deppending on the process's step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batchnormalization(X, eps=1e-8, W=None, b=None):\n",
    "    \n",
    "    if X.get_shape().ndims == 4:\n",
    "        mean = tf.reduce_mean(X, [0,1,2])\n",
    "        standar_desviation = tf.reduce_mean(tf.square(X-mean), [0,1,2])\n",
    "        X = (X - mean) / tf.sqrt(standar_desviation + eps)\n",
    "        \n",
    "        if W is not None and b is not None:\n",
    "            W = tf.reshape(W, [1,1,1,-1])\n",
    "            b = tf.reshape(b, [1,1,1,-1])\n",
    "            X = X*W + b\n",
    "    \n",
    "    elif X.get_shape().ndims == 2:\n",
    "        mean = tf.reduce_mean(X, 0)\n",
    "        standar_desviation = tf.reduce_mean(tf.square(X-mean), 0)\n",
    "        X = (X - mean) / tf.sqrt(standar_desviation + eps)\n",
    "        \n",
    "        if W is not None and b is not None:\n",
    "            W = tf.reshape(W, [1,-1])\n",
    "            b = tf.reshape(b, [1,-1])\n",
    "            X = X*W + b\n",
    "    \n",
    "    return X\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Leaky Relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The Rectifier (Rectified Linear Unit) is an activation defined as max(0,x). This is also known as a ramp function.\n",
    "The Leaky Relu activation is a variant from the Relu and it is defined as max(x,alpha*x). This Leaky Relu function has been probed to work well with images avoiding the problem of dying ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def leakyRelu(X, alpha=0.2):\n",
    "    return tf.maximum(X,tf.multiply(X, alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# BCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the cross entropy between y and y'. This value is going to be used by the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def bce(x, z):\n",
    "    x = tf.clip_by_value(x, 1e-7, 1. - 1e-7)\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = x, labels = z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# GENERATOR AND DISCRIMINATOR FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This two methods basically consists on the two differents multilayers that are going to be used in a GAN network, both of them are going to use weights initialized with a random normal desviation of 0,02. We have used relu as the activation function for the generator and leakyRelu for the discriminator. In each step we concat the Y labels, as Y or as yb, and they act like the bias in this network. We have only used two conv (conv2d and conv2d_transpose) to simplify the results and to reduce computational time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def MultilayerPerceptronGenerator(Z, Y, batch_size):\n",
    "     \n",
    "    kernel_W1 = [int(Z.get_shape()[1] + Y.get_shape()[1]), dim_W1]\n",
    "    kernel_W2 = [dim_W1 + int(Y.get_shape()[1]), dim_W2*7*7]\n",
    "    kernel_W3 = [5, 5, dim_W3, dim_W2 +  int(Y.get_shape()[1])]\n",
    "    kernel_W4 = [5, 5, dim_channel, dim_W3 +  int(Y.get_shape()[1])]\n",
    "    \n",
    "    gen_W1 = tf.get_variable(\"gen_W1\", kernel_W1, initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "    gen_W2 = tf.get_variable(\"gen_W2\", kernel_W2, initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "    gen_W3 = tf.get_variable(\"gen_W3\", kernel_W3, initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "    gen_W4 = tf.get_variable(\"gen_W4\", kernel_W4, initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "    \n",
    "    yb = tf.reshape(Y, [batch_size, 1, 1, int(Y.get_shape()[1])])\n",
    "    Z = tf.concat([Z, Y], axis=1) \n",
    "    op1 = tf.nn.relu(batchnormalization(tf.matmul(Z, gen_W1)))\n",
    "    op1 = tf.concat([op1, Y], axis=1)\n",
    "    op2 = tf.nn.relu(batchnormalization(tf.matmul(op1, gen_W2)))\n",
    "    op2 = tf.reshape(op2, [batch_size, 7, 7, dim_W2])\n",
    "    op2 = tf.concat([op2, yb*tf.ones([batch_size, 7, 7, int(Y.get_shape()[1])])], axis = 3)\n",
    "    \n",
    "    op3 = tf.nn.conv2d_transpose(op2, gen_W3, output_shape=[batch_size, 14, 14, dim_W3], strides=[1,2,2,1])\n",
    "    op3 = tf.nn.relu(batchnormalization(op3))\n",
    "    op3 = tf.concat([op3, yb*tf.ones([batch_size, 14, 14, Y.get_shape()[1]])], axis = 3)\n",
    "    op4 = tf.nn.conv2d_transpose(op3, gen_W4, output_shape=[batch_size, 28, 28, dim_channel], strides=[1,2,2,1])\n",
    "    \n",
    "    \n",
    "    return op4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def MultilayerPerceptronDiscriminator(image, Y, batch_size):\n",
    "    \n",
    "    kernel_W1 = [5, 5, dim_channel + int(dim_y), dim_W3]\n",
    "    kernel_W2 = [5, 5, dim_W3 + int(dim_y), dim_W2]\n",
    "    kernel_W3 = [dim_W2*7*7 + int(dim_y), dim_W1]\n",
    "    kernel_W4 = [dim_W1 + int(dim_y), 1]\n",
    "    \n",
    "    dis_W1 = tf.get_variable(\"dis_W1\", kernel_W1, initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "    dis_W2 = tf.get_variable(\"dis_W2\", kernel_W2, initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "    dis_W3 = tf.get_variable(\"dis_W3\", kernel_W3, initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "    dis_W4 = tf.get_variable(\"dis_W4\", kernel_W4, initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "\n",
    "    yb = tf.reshape(Y, tf.stack([batch_size, 1, 1, int(Y.get_shape()[1])]))\n",
    "    X = tf.concat([image, yb*tf.ones([batch_size, 28, 28, int(Y.get_shape()[1])])], axis = 3)\n",
    "    op1 = leakyRelu( tf.nn.conv2d( X, dis_W1, strides=[1, 2, 2, 1], padding='SAME'))\n",
    "    op1 = tf.concat([op1, yb*tf.ones([batch_size, 14, 14, int(Y.get_shape()[1])])], axis = 3)\n",
    "    op2 = leakyRelu( tf.nn.conv2d( op1, dis_W2, strides=[1, 2, 2, 1], padding='SAME'))\n",
    "    op2 = tf.reshape(op2, [batch_size, -1])\n",
    "    op2 = tf.concat([op2, Y], axis = 1)\n",
    "    op3 = leakyRelu(batchnormalization(tf.matmul(op2, dis_W3)))\n",
    "    op3 = tf.concat([op3, Y], axis = 1)\n",
    "    \n",
    "    p = tf.nn.sigmoid(tf.matmul(op3, dis_W4))\n",
    "    return p, op3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is going to connect the generator and discriminator and calculate the different variables to optimize during our training. This variables are calculated with the BCE functions that calculate the cross entropy between the results from the discriminator (with the real or generated image) and the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def createModel(batch_size):\n",
    "    \n",
    "    Z = tf.placeholder(tf.float32, [batch_size, dim_z])\n",
    "    Y = tf.placeholder(tf.float32, [batch_size, dim_y])\n",
    "\n",
    "    image_real = tf.placeholder(tf.float32, [batch_size] + image_shape)\n",
    "\n",
    "    op4_generated = MultilayerPerceptronGenerator(Z,Y, batch_size)\n",
    "    image_generate = tf.nn.sigmoid(op4_generated)\n",
    "\n",
    "    with tf.variable_scope(\"discriminator_variables\") as scope:\n",
    "        p_real, raw_real = MultilayerPerceptronDiscriminator(image_real, Y, batch_size)\n",
    "        scope.reuse_variables()\n",
    "        p_gen, raw_gen = MultilayerPerceptronDiscriminator(image_generate, Y, batch_size)\n",
    "\n",
    "\n",
    "    dis_cost_real = bce(raw_real, tf.ones_like(raw_real))\n",
    "    dis_cost_gen = bce(raw_gen, tf.zeros_like(raw_gen))\n",
    "    dis_cost = dis_cost_real + dis_cost_gen\n",
    "\n",
    "    gen_cost = bce (raw_gen, tf.ones_like(raw_gen))\n",
    "\n",
    "    return Z, Y, image_real, dis_cost, gen_cost, p_real, p_gen\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AdamOptimizer is used with a learning rate of 0.0002 and a beta of 0.5. These parameters determine how fast change the weights and the bias. This function computes both, the optimizer from the generator and from the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimizer_function(d_cost_tf, g_cost_tf, dis_vars, gen_vars):\n",
    "    train_op_dis = tf.train.AdamOptimizer(learning_rate, beta1=0.5).minimize(d_cost_tf, var_list=dis_vars)\n",
    "    train_op_gen = tf.train.AdamOptimizer(learning_rate, beta1=0.5).minimize(g_cost_tf, var_list=gen_vars)\n",
    "    \n",
    "    return train_op_dis, train_op_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the sample generator that is going to be used for extracting a sample during the training. This sample allows us to see how the generator is rectifing and creating more accurate image as the training progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_creator(dimension):\n",
    "    \n",
    "    Z = tf.placeholder(tf.float32, [dimension, dim_z])\n",
    "    Y = tf.placeholder(tf.float32, [dimension, dim_y])\n",
    "    \n",
    "    op4 = MultilayerPerceptronGenerator(Z,Y,dimension)\n",
    "    image = tf.nn.sigmoid(op4)\n",
    "    \n",
    "    return Z,Y,image\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aux functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def OneHot(X, n=None, negative_class=0.):\n",
    "    X = np.asarray(X).flatten()\n",
    "    if n is None:\n",
    "        n = np.max(X) + 1\n",
    "    Xoh = np.ones((len(X), n)) * negative_class\n",
    "    Xoh[np.arange(len(X)), X] = 1.\n",
    "    return Xoh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def save_visualization(X, nh_nw, save_path='tmp/sample.jpg'):\n",
    "    h,w = X.shape[1], X.shape[2]\n",
    "    img = np.zeros((h * nh_nw[0], w * nh_nw[1], 3))\n",
    "    for n,x in enumerate(X):\n",
    "        j = n // nh_nw[1]\n",
    "        i = n % nh_nw[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w, :] = x\n",
    "        \n",
    "        \n",
    "    scipy.misc.imsave(save_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load the DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "data_dir = 'data/'\n",
    "def mnist():\n",
    "    fd = open(os.path.join(data_dir,'train-images.idx3-ubyte'))\n",
    "    loaded = np.fromfile(file=fd,dtype=np.uint8)\n",
    "    trX = loaded[16:].reshape((60000,28*28)).astype(float)\n",
    "\n",
    "    fd = open(os.path.join(data_dir,'train-labels.idx1-ubyte'))\n",
    "    loaded = np.fromfile(file=fd,dtype=np.uint8)\n",
    "    trY = loaded[8:].reshape((60000))\n",
    "\n",
    "    fd = open(os.path.join(data_dir,'t10k-images.idx3-ubyte'))\n",
    "    loaded = np.fromfile(file=fd,dtype=np.uint8)\n",
    "    teX = loaded[16:].reshape((10000,28*28)).astype(float)\n",
    "\n",
    "    fd = open(os.path.join(data_dir,'t10k-labels.idx1-ubyte'))\n",
    "    loaded = np.fromfile(file=fd,dtype=np.uint8)\n",
    "    teY = loaded[8:].reshape((10000))\n",
    "\n",
    "    trY = np.asarray(trY)\n",
    "    teY = np.asarray(teY)\n",
    "\n",
    "    return trX, teX, trY, teY\n",
    "\n",
    "def mnist_with_valid_set():\n",
    "    trX, teX, trY, teY = mnist()\n",
    "\n",
    "    train_inds = np.arange(len(trX))\n",
    "    np.random.shuffle(train_inds)\n",
    "    trX = trX[train_inds]\n",
    "    trY = trY[train_inds]\n",
    "    vaX = trX[50000:]\n",
    "    vaY = trY[50000:]\n",
    "    trX = trX[:50000]\n",
    "    trY = trY[:50000]\n",
    "\n",
    "    return trX, vaX, teX, trY, vaY, teY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set of : (50000, 784)\n",
      "Train label of : (50000,)\n",
      "Test set of : (10000, 784)\n",
      "Test label of : (10000,)\n",
      "Validation set of : (10000, 784)\n",
      "Validation label of : (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_data, validation_data, test_data, train_label, validation_label, test_label = mnist_with_valid_set()\n",
    "print(\"Train set of : \" + str(train_data.shape))\n",
    "print(\"Train label of : \" + str(train_label.shape))\n",
    "print(\"Test set of : \" + str(test_data.shape))\n",
    "print(\"Test label of : \" + str(test_label.shape))\n",
    "print(\"Validation set of : \" + str(validation_data.shape))\n",
    "print(\"Validation label of : \" + str(validation_label.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "learning_rate = 0.0002\n",
    "batch_size = 128\n",
    "image_shape = [28,28,1]\n",
    "dim_z = 100\n",
    "dim_W1 = 1024\n",
    "dim_W2 = 128\n",
    "dim_W3 = 64\n",
    "dim_channel = 1\n",
    "dim_y = 10\n",
    "visualize_dimension=196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"training_part\") as scope:\n",
    "    Z_tf, Y_tf, image_tf, d_cost_tf, g_cost_tf, p_real, p_gen = createModel(batch_size)\n",
    "    session = tf.InteractiveSession()\n",
    "    saver = tf.train.Saver(max_to_keep=10)\n",
    "\n",
    "    scope.reuse_variables()\n",
    "    Z_sample, Y_sample, image_sample = sample_creator(visualize_dimension)\n",
    "\n",
    "dis_vars = filter(lambda x: x.name.startswith(scope.name+'/dis'), tf.global_variables())\n",
    "gen_vars = filter(lambda x: x.name.startswith(scope.name+'/gen'), tf.global_variables())\n",
    "dis_vars = [i for i in dis_vars]\n",
    "gen_vars = [i for i in gen_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_op_dis, train_op_gen = optimizer_function(d_cost_tf, g_cost_tf, dis_vars, gen_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Z_np_sample = np.random.uniform(-1, 1, size=(visualize_dimension, dim_z))\n",
    "Y_np_sample = OneHot(np.random.randint(10, size=[visualize_dimension]))\n",
    "iterations = 0\n",
    "k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Information variables of the training process\n",
    "sample_creation = 200 #Iteration where a sample is going to be created\n",
    "show_information = 25 #Iteration where the information is going to be showed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the training process\n",
      "========== Showing information =========\n",
      "iteration: 0\n",
      "gen loss: 0.59991\n",
      "discrim loss: 1.43471\n",
      "Average P(real)= 0.488061\n",
      "Average P(gen)= 0.486245\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'image/sample_0000.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-76160a12e68d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mgenerated_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_sample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mZ_sample\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mZ_np_sample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_sample\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mY_np_sample\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mgenerated_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgenerated_sample\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0msave_visualization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerated_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'image/sample_%04d.jpg'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msample_creation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0miterations\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-f217eb10924c>\u001b[0m in \u001b[0;36msave_visualization\u001b[1;34m(X, nh_nw, save_path)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\nacho\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\scipy\\misc\\pilutil.py\u001b[0m in \u001b[0;36mimsave\u001b[1;34m(name, arr, format)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoimage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nacho\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   1723\u001b[0m             \u001b[1;31m# Open also for reading (\"+\"), because TIFF save_all\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1724\u001b[0m             \u001b[1;31m# writer needs to go back and edit the written data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1725\u001b[1;33m             \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w+b\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1726\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1727\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'image/sample_0000.jpg'"
     ]
    }
   ],
   "source": [
    "print(\"Starting the training process\")\n",
    "for epoch in range(n_epochs):\n",
    "    index = np.arange(len(train_label))\n",
    "    np.random.shuffle(index)\n",
    "    train_data = train_data[index]\n",
    "    train_label = train_label[index]\n",
    "\n",
    "    for start, end in zip(\n",
    "            range(0, len(train_label), batch_size),\n",
    "            range(batch_size, len(train_label), batch_size)\n",
    "            ):\n",
    "\n",
    "        Xs = train_data[start:end].reshape( [-1, 28, 28, 1]) / 255.\n",
    "        Ys = OneHot(train_label[start:end])\n",
    "        Zs = np.random.uniform(-1, 1, size=[batch_size, dim_z]).astype(np.float32)\n",
    "\n",
    "        if np.mod( iterations, k ) != 0:\n",
    "            _, gen_loss_val = session.run([train_op_gen, g_cost_tf],feed_dict={Z_tf:Zs,Y_tf:Ys})\n",
    "            discrim_loss_val, p_real_val, p_gen_val = session.run([d_cost_tf,p_real,p_gen],feed_dict={Z_tf:Zs, image_tf:Xs, Y_tf:Ys})\n",
    "\n",
    "        else:\n",
    "            _, discrim_loss_val = session.run([train_op_dis, d_cost_tf],feed_dict={Z_tf:Zs,Y_tf:Ys,image_tf:Xs})\n",
    "            gen_loss_val, p_real_val, p_gen_val = session.run([g_cost_tf, p_real, p_gen],feed_dict={Z_tf:Zs, image_tf:Xs, Y_tf:Ys})\n",
    "\n",
    "        if np.mod(iterations, show_information) == 0:\n",
    "            print(\"========== Showing information =========\")\n",
    "            print(\"iteration:\", iterations)\n",
    "            print(\"gen loss:\", gen_loss_val)\n",
    "            print(\"discrim loss:\", discrim_loss_val)\n",
    "            print(\"Average P(real)=\", p_real_val.mean())\n",
    "            print(\"Average P(gen)=\", p_gen_val.mean())\n",
    "\n",
    "        if np.mod(iterations, sample_creation) == 0:\n",
    "            generated_sample = session.run(image_sample,feed_dict={Z_sample:Z_np_sample,Y_sample:Y_np_sample})\n",
    "            generated_samples = (generated_sample + 1.)/2.\n",
    "            save_visualization(generated_samples, (14,14), save_path='image/sample_%04d.jpg' % int(iterations/sample_creation))\n",
    "\n",
    "        iterations += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
